\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{hyperref}

\title{Exploring Bacon's Law; Actors and their Associates Connected through Film}
\author{Tai Poole, Nabhan Rashid, Danny Tran}
\date{March 5, 2025}

\begin{document}

\maketitle

\section{Problem Description}
There is a well known pop culture game known as the ``Bacon Number Game." The Bacon Number Game revolves around the conjecture of Bacon’s Law that every actor in Hollywood is connected to Kevin Bacon through 6 degrees of separation or less (1). The game is then to find this path. If we consider each actor a vertex in a graph, two actors are related when they have acted in the same movie, which we define as an edge. The degree of separation is defined as the smallest path length between two actors. Note that similar to the definition of a path for graphs, Kevin Bacon is the only person with a Kevin Bacon number of 0. One might also know this system by the similar game in math, the Erdős number, or the similar popular game The Wiki game (2). \\\\
It’s an amusing thought experiment, suggesting that Hollywood isn’t that big and most of our movies are just the same few actors over and over again or that at some point, every actor in Hollywood has worked with each other. As our group was discussing it, we also reflected on why the focus was Kevin Bacon, an actor we did not feel was very popular anymore. This was because the Bacon number was conceived in 1994, back when Kevin Bacon was a much larger presence in pop culture. Because of this, we wanted to broaden the Bacon number's concept to the degrees of separation of \emph{any} two actors, to make it more generalizable and timeless. \textbf{In this project, we seek to understand the level of interconnectivity between professionals in the movie industry, and to examine the legitimacy of the famous Bacon’s Law. In doing so we also hope to modernize the Bacon's Law, and show it holds even when only considering recent movies, and alive actors.}
\section{The Datasets}
For our domain, we are going to use the IMDb movie datasets (3). To make our connections we will use the [title.principals.tsv.gz] database; which contains every role in the various IMDb movies along with associated Actor IDs, Movie IDs and their role names. Additionally, we are using two additional databases to match Movie IDs with Movie Names and Actor IDs and Actor names [name.basics.tsv.gz] and [title.basics.tsv.gz]. These databases are also compiled to give restrictions on the path we find, using attributes such as their deathYear to filter out dead actors. Below is an example of the [title.principals.tsv.gz] dataset.
\begin{verbatim}
    tconst    ordering    nconst    category    job    characters
tt0000001    1    nm1588970    self    \N    ["Self"]
tt0000002    1    nm0721526    director    \N    \N
tt0000005    1    nm0443482    actor    \N    ["Blacksmith"]
\end{verbatim}
The data from the three datasets are TSV files with string IDs identifying actors and movies. Actors are identified with alphanumeric strings beginning with ``nm” (such as nm0000001 for ``Fred Astaire”) and movies are identified with similar strings beginning with ``tt” (such as tt0133093 for ``The Matrix”).

\section{Computational Overview}
The graph itself will be represented as an SQL database. To be more specific, an \verb+sqlite+ database. This was for various reasons, but chief among them was size constraints. We tried an entirely NetworkX graph at the start of the project, but we quickly realized the 12GB of RAM it required was infeasible. On the other hand, the SQL database requires 0.5GB of \emph{hard drive} space and keeps a fast processing speed. To create this database, we have the file \verb+sql_processing.py+ which is split into two parts. Then the graph processing. Once the graph is initialized our program is designed to traverse the graph using breadth-first search in \verb+graph_processing+. This file is built to find the shortest path between two actors (And also find the shortest path between two actors given a variety of restrictions) and to create a \verb+NetworkX+ graph to be passed for display. Finally, to make the data more palatable, the file \verb+gui_interface.py+ is where we use \verb+tkinter+, \verb+matplotlib+, and \verb+NetworkX+ in tandem to free the user from staring at text-based information and typing their commands.

\subsection{SQL Database Creation}

The first step in initializing the SQL graph database is compiling the TSV files into an easy-to-access structure. This is the duty of \verb!compile_full_data! which assumes the existence and location of the three TSV files, and uses them to fill the SQL database with the same information, but with random access. The files are read using the \verb!csv! module, changing the delimiter to a tab (\verb!\t!) instead of a comma. Any sqlite database call and insertion is done with the \verb!sql.Connection!, \verb!sql.Connection.commit()!, \verb!sql.Cursor!, and \verb!sql.Cursor.execute()! classes and methods.

This database is then used to compile a graph of actors and movies, with edges where an actor has played a part in a movie. It is in this step of the process where the filtering happens. Within the IMDb database there are many \emph{media} and \emph{people}, but not all of them are movies and actors. There are many TV episodes, directors, camera people, e.t.c. This is why the data is filtered using attributes of the previously created database such as \verb+category+ (see above example of [title.principals.tsv.gz]), and primaryProfession. We also ensure the nodes have helpful attributes, such as startYear for movies and deathYear for actors, which will be used in later processing. It is with this use SQL shows its strength, allowing fast and elegant filtering of data for our use.

The SQL graph database is made of three tables, one for movies, one for actors, and one for edges. The former two have the above stated attributes, and are indexed by their respective IDs for fast lookup times. The latter is an \verb+adjacency_list+, chosen due to the high amount of queries to what nodes are connected to a specific node (Rather than querying whether two nodes are connected, for which an \verb+adjacency_matrix+ is useful). The edges are between IDs, and because the edges are between IDs, this allows for a handy optimization, as the IDs are guaranteed to be unique, indexing them means extremely fast lookup times for the adjacent nodes. It is for this reason the SQL graph representation is so fast, and why it was our best choice for data structure.

\subsection{The Graph Processing}

Now that the graph is created, we want to find the shortest path between two actors. There are various helper functions assisting the pathfinding, but there are two functions actually doing the work, \verb+get_path+ and \verb+get_restricted_path+ for a normal, and restricted path respectively. The algorithm in use is a Breadth First Search, and makes use of the \verb+deque+ data structure provided by Python. During the restricted path search, we filter in only nodes matching the restrictions we desire before adding it to the queue. This is checked for by using an SQL query. We decided to keep both the restricted path finder and the normal path finder as the normal path finder is significantly faster in all cases.

We felt it would be best to \emph{show} the user what their path looks like, instead of just listing the movies and actors. This is why once a path is found, the \verb!make_networkx_graph! method takes the path, and returns a colour-coded graph. Green for the end-points, salmon for the movies, and bisque for the people. This is done with the \verb+networkx.Graph+ class. Though we couldn't use it for the large database, its \verb!draw! methods made it invaluable in representing graphs, and the memory problem it created doesn't exist on such a small scale.

\subsection{The User Interface}
The GUI (graphical user interface) is a window that was created using the \verb!tkinter! toolkit. Tkinter organizes their windows into groups of \verb!Frame! objects, which then have widgets packed onto them. Frames objects organize the layout in a way similar to "div"s and "span"s in html. Widgets are elements of the windowthat can be visual such as \verb!Label!, \verb!Text!, as well as interactive for input, with widgets \verb!Entry!, \verb!Button!, and \verb!OptionMenu!. It is divided into 2 main sections: The input frame (left) and the output frame (right). The input frame has information about it, as well as all of the input fields. This is 2 input fields, one for each actor, a dropdown menu and another input field for the filters on the data, and a button to submit the query. This query is processed for correct input, and then calls our other files such as \verb!get_restricted_path! from graph\_processing, or functions from sql\_processing to get the data. The output frame has "the canvas", as well as a small box at the bottom that displays the success/failure of the query. The canvas is where the graph is plotted. This graph is drawn using networkx's \verb!draw! method, which is an extension of the \verb!matplotlib! library. Usually matplotlib displays its visualizations in a browser tab, so we had to write our own custom matplotlib integration to allow us to render our images onto the GUI instead, and in a way that is "pretty" and readable. Since matplotlib figures are not designed to be dynamically redrawn out of the box, this integration also required managing the memory properly of the graphs and figures to prevent memory leaking and unexpected behaviour. All of this to say, the GUI is an intermediary between the user and algorithms, which makes the interaction simpler and more accessible, as well as provide an easy to understand visualization for our graph paths.

\section{Obtaining the Datasets and Running the Program}
If you so desire you can build the full graph dataset from scratch by downloading the files in the IMDb dataset (3) then running the file \verb!sql_processing.py! and following the instructions given. I don't recommend this method unless you are really curious, as this can take upwards of 15 minutes for the first part of dataset creation, and up to 5 minutes for the second.

Instead we will provide the graph dataset. It will be called \textbf{actors\_and\_movies.db}, and please keep it that way. Then put this file into a folder \textbf{data\_files} within the same directory as \verb!main.py!.

To access the zip file of the file necessary to run the program, please access this link: \href{https://utoronto-my.sharepoint.com/:u:/g/personal/nabhan_rashid_mail_utoronto_ca/EYMbuqB8-ARIrHxDK7YhbWkBS4cH6Imba-6myQPnr1z57w?e=JQY8F9}{OneDrive Link}

These files include the original data sets from IMDb, and the \verb!main_database.db! created during the first step of the

This program has 3 dependencies, they are listed in \verb!requirements.txt!, but they will also be listed here:
\begin{enumerate}
\item \verb!networkx==3.4.2!
\item \verb!matplotlib==3.10.1!
\item \verb!scipy==1.15.0!
\end{enumerate}
These can be found through PyCharm, so we do not believe they require special installation instructions.

Upon running this program, you can expect to see a new window open (You might have to click it from the taskbar) with interactable boxes on the left, and an empty space for the graph on the right. To start with, we recommend choosing two actors without any restrictions, just to get the hang of the program. Type their names in within the given space, then click \verb+Go!+ After getting used to it, you can add restrictions, perhaps find a path with movies only made after 2000, or a path between two dead actors.

\section{Changes to the Project Plan}
One of the biggest changes to our project plan was our decision to use an SQL graph database instead of a \verb!networkx! graph because of the unrealized scale of our data. This allows our program to take much less memory and processing time. We also decided to add onto our plan the restrictions, specifically restrictions on age to further our goal of finding out if we can \emph{modernize} the Kevin Bacon number.

\section{Discussion}
We did manage to find out the Kevin Bacon Theory is most likely correct. From our testing, we could only break Bacon's law if we added the restrictions that all connecting actors had to be deceased, with only 7 degrees of seperation as our max, which is close to the conjecture, despite being a much looser bound than the original theory. From our unrestricted testing, we were unable to get a number higher than 4, despite our best efforts to find the most obscure actors we could. An unexpected development we found was being able to connect some large Bollywood actors with Hollywood actors, further increasing the domain of the original problem while still adhering to 6 degrees of seperation. However, we couldn't quite accomplish our second goal, to modernize the Kevin Bacon number, as adding restrictions steeply increases processing time. This did prove a point though, old actors and their movies often make up the backbone of a path between actors, as without them the path quickly becomes too long to follow.

Some struggles we came to were mostly to do with speed and the GUI.

When it came to speed, we didn't want to budge on the SQL network, because the trade-off would be RAM. As such we tried out different ideas with the \verb!schema!. Things like double indexing the tables, or changing the index we refer to, and we actually started off with a adjacency matrix for the edge table, because that's how the database (\verb!title.principals.tsv.gz!) came. At first we were indexing once over both ends of the edge (An \verb!actor_id! and a \verb!movie_id!), but after doing some heavy research into SQL, we realized it would be faster to index both the ends separately. Finally, we realized if we sacrificed some pre-processing time (about 5 minutes), we could instead use an adjacency list, that was significantly faster than anything else we'd tried before, and it's what allowed us to scale to the entire movie database when we used to only use a tenth!

For our GUI, there were a couple small challenges, such as designing the layout, creating a visually appealing UI while not being distracting, and choosing the best layout to draw the paths with so that they minimize label overlap. However, the majority of issues came with using \verb!matplotlib! to render things properly. There seemed to be a plethora of strange hurdles we overcame, such as graphs not taking up the whole canvas, labels and paths being cropped, memory issues with drawing multiple times with \verb!matplotlib!, and the fact that since we were rendering onto a \verb!tkinter! window, a lot of the common fixes for these problems weren't so trivial. There was a lot of trial and error present with fixing these solutions, since some of our issues became quite niche when combining the behaviours of all of the libraries we used. However, by fixing these problems in the development phase, we took the burden of complexity off the shoulders of the user, and created a simple and intuitive program which we are proud of.

Overall we are very proud of the program, and we think we have satisfied the curiosity with first approached this problem with. If we were to further pursue this questioning, we would try to see what extra data would shorten the path length, such as including TV shows, and including stage-people.
\section{Bibliography}

(1) “Six Degrees of Kevin Bacon.” Wikipedia, https://en.wikipedia.org/wiki/Six\_Degrees\_of\_Kevin\_Bacon. Accessed 1 March 2025.\\\\

(2) “Wikipedia:Wiki Game.” Wikipedia, https://en.wikipedia.org/wiki/Wikipedia:Wiki\_Game. Accessed 1 March 2025.\\\\

(2) Chayes, Lincoln, et al. “Erdős number.” Wikipedia, https://en.wikipedia.org/wiki/Erd\%C5\%91s\_number. Accessed 1 March 2025.\\\\

(3) IMDB. “IMDb Data Files.” IMDb Data Files Download, 2024, https://datasets.imdbws.com/. Accessed 1 March 2025.\\\\



IMDb has asked that we source their dataset as such:\\
Information courtesy of
IMDb
(https://www.imdb.com).
Used with permission.

\end{document}
